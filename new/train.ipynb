{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = pd.read_csv('train_preprocess_v1.csv').values\n",
    "test_data_1 = pd.read_csv('test_preprocess_v1.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2 = pd.read_csv('train_preprocess_v2.csv').values\n",
    "test_data_2 = pd.read_csv('test_preprocess_v2.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_3 = pd.read_csv('train_preprocess_v3.csv').values\n",
    "test_data_3 = pd.read_csv('test_preprocess_v3.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_4 = pd.read_csv('train_preprocess_v4.csv').values\n",
    "test_data_4 = pd.read_csv('test_preprocess_v4.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 920), (7000, 1537), (7000, 38), (7000, 1752))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1.shape, train_data_2.shape, train_data_3.shape, train_data_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([train_data_1, train_data_2, train_data_3, train_data_4], axis=1)\n",
    "X_test = np.concatenate([test_data_1, test_data_2, test_data_3, test_data_4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_df = pd.read_csv('label.csv', header=None)\n",
    "y_train = label_df[0].values\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502 features with a correlation magnitude greater than 0.90.\n",
      "\n",
      "Removed 502 features.\n"
     ]
    }
   ],
   "source": [
    "from feature_selector import FeatureSelector\n",
    "\n",
    "fs = FeatureSelector(data=pd.DataFrame(X_train), labels=y_train)\n",
    "\n",
    "fs.identify_collinear(correlation_threshold=0.90)\n",
    "\n",
    "train_new_df = fs.remove(methods = ['collinear'])\n",
    "test_new_df = pd.DataFrame(X_test)[train_new_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "selector = VarianceThreshold(0.2)\n",
    "X_train = selector.fit_transform(imputer.fit_transform(train_new_df.replace([np.inf, -np.inf], np.nan).values))\n",
    "X_test = selector.transform(imputer.fit_transform(test_new_df.replace([np.inf, -np.inf], np.nan).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                                   class_weight=None, criterion='entropy',\n",
       "                                   max_depth=None,\n",
       "                                   max_features=0.9000000000000001,\n",
       "                                   max_leaf_nodes=None, max_samples=None,\n",
       "                                   min_impurity_decrease=0.0,\n",
       "                                   min_impurity_split=None, min_samples_leaf=1,\n",
       "                                   min_samples_split=2,\n",
       "                                   min_weight_fraction_leaf=0.0,\n",
       "                                   n_estimators=100, n_jobs=None,\n",
       "                                   oob_score=False, random_state=None,\n",
       "                                   verbose=0, warm_start=False),\n",
       "    n_features_to_select=None, step=0.15000000000000002, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold\n",
    "\n",
    "rfe = RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.9000000000000001, n_estimators=100), step=0.15000000000000002)\n",
    "\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 1640), (2000, 1640))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, rfe.support_].shape, X_test[:, rfe.support_].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, rfe.support_]\n",
    "X_test = X_test[:, rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                                   class_weight=None, criterion='entropy',\n",
       "                                   max_depth=None,\n",
       "                                   max_features=0.9000000000000001,\n",
       "                                   max_leaf_nodes=None, max_samples=None,\n",
       "                                   min_impurity_decrease=0.0,\n",
       "                                   min_impurity_split=None, min_samples_leaf=1,\n",
       "                                   min_samples_split=2,\n",
       "                                   min_weight_fraction_leaf=0.0,\n",
       "                                   n_estimators=100, n_jobs=None,\n",
       "                                   oob_score=False, random_state=None,\n",
       "                                   verbose=0, warm_start=False),\n",
       "    n_features_to_select=None, step=0.15000000000000002, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.9000000000000001, n_estimators=100), step=0.15000000000000002)\n",
    "\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 820), (2000, 820))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, rfe.support_].shape, X_test[:, rfe.support_].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, rfe.support_]\n",
    "X_test = X_test[:, rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                                   class_weight=None, criterion='entropy',\n",
       "                                   max_depth=None,\n",
       "                                   max_features=0.9000000000000001,\n",
       "                                   max_leaf_nodes=None, max_samples=None,\n",
       "                                   min_impurity_decrease=0.0,\n",
       "                                   min_impurity_split=None, min_samples_leaf=1,\n",
       "                                   min_samples_split=2,\n",
       "                                   min_weight_fraction_leaf=0.0,\n",
       "                                   n_estimators=100, n_jobs=None,\n",
       "                                   oob_score=False, random_state=None,\n",
       "                                   verbose=0, warm_start=False),\n",
       "    n_features_to_select=None, step=0.15000000000000002, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.9000000000000001, n_estimators=100), step=0.15000000000000002)\n",
    "\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 102), (2000, 102))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, rfe.support_].shape, X_test[:, rfe.support_].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, rfe.support_]\n",
    "X_test = X_test[:, rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_macroF1_lgb(truth, predictions):  \n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.363979\tvalid_0's macroF1: 0.82394\n",
      "[200]\tvalid_0's multi_logloss: 0.322392\tvalid_0's macroF1: 0.838802\n",
      "[300]\tvalid_0's multi_logloss: 0.307682\tvalid_0's macroF1: 0.838982\n",
      "[400]\tvalid_0's multi_logloss: 0.301665\tvalid_0's macroF1: 0.84607\n",
      "[500]\tvalid_0's multi_logloss: 0.30116\tvalid_0's macroF1: 0.852559\n",
      "[600]\tvalid_0's multi_logloss: 0.303997\tvalid_0's macroF1: 0.85733\n",
      "Early stopping, best iteration is:\n",
      "[514]\tvalid_0's multi_logloss: 0.300795\tvalid_0's macroF1: 0.852559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.339705\tvalid_0's macroF1: 0.844847\n",
      "[200]\tvalid_0's multi_logloss: 0.287422\tvalid_0's macroF1: 0.858506\n",
      "[300]\tvalid_0's multi_logloss: 0.272318\tvalid_0's macroF1: 0.867367\n",
      "[400]\tvalid_0's multi_logloss: 0.264306\tvalid_0's macroF1: 0.874621\n",
      "[500]\tvalid_0's multi_logloss: 0.259068\tvalid_0's macroF1: 0.876463\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's multi_logloss: 0.260764\tvalid_0's macroF1: 0.879478\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.372062\tvalid_0's macroF1: 0.816664\n",
      "[200]\tvalid_0's multi_logloss: 0.327194\tvalid_0's macroF1: 0.834483\n",
      "[300]\tvalid_0's multi_logloss: 0.313161\tvalid_0's macroF1: 0.844011\n",
      "[400]\tvalid_0's multi_logloss: 0.304635\tvalid_0's macroF1: 0.852278\n",
      "[500]\tvalid_0's multi_logloss: 0.301868\tvalid_0's macroF1: 0.856207\n",
      "[600]\tvalid_0's multi_logloss: 0.302268\tvalid_0's macroF1: 0.86228\n",
      "Early stopping, best iteration is:\n",
      "[571]\tvalid_0's multi_logloss: 0.301115\tvalid_0's macroF1: 0.86043\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.350829\tvalid_0's macroF1: 0.826303\n",
      "[200]\tvalid_0's multi_logloss: 0.294887\tvalid_0's macroF1: 0.853176\n",
      "[300]\tvalid_0's multi_logloss: 0.281867\tvalid_0's macroF1: 0.855541\n",
      "[400]\tvalid_0's multi_logloss: 0.276037\tvalid_0's macroF1: 0.860008\n",
      "[500]\tvalid_0's multi_logloss: 0.274571\tvalid_0's macroF1: 0.86738\n",
      "Early stopping, best iteration is:\n",
      "[463]\tvalid_0's multi_logloss: 0.274219\tvalid_0's macroF1: 0.86738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.338263\tvalid_0's macroF1: 0.834728\n",
      "[200]\tvalid_0's multi_logloss: 0.289863\tvalid_0's macroF1: 0.844198\n",
      "[300]\tvalid_0's multi_logloss: 0.273192\tvalid_0's macroF1: 0.855891\n",
      "[400]\tvalid_0's multi_logloss: 0.263782\tvalid_0's macroF1: 0.866357\n",
      "[500]\tvalid_0's multi_logloss: 0.261585\tvalid_0's macroF1: 0.869685\n",
      "[600]\tvalid_0's multi_logloss: 0.261837\tvalid_0's macroF1: 0.874923\n",
      "Early stopping, best iteration is:\n",
      "[556]\tvalid_0's multi_logloss: 0.2608\tvalid_0's macroF1: 0.871309\n",
      "[0.8525590187332979, 0.8794782418353811, 0.8604297095336824, 0.8673799353666426, 0.871308923193484]\n",
      "0.8662311657324976 0.00919970451020056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "\n",
    "model_list_1 = []\n",
    "score_list = []\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    model = lgb.LGBMClassifier(n_estimators=1000, objective='multiclass', num_leaves=63,\n",
    "                               max_depth=7, learning_rate=0.03, subsample=0.8, colsample_bytree=0.8)\n",
    "    eval_set = (X_train[test_index], y_train[test_index])\n",
    "    model.fit(X=X_train[train_index], y=y_train[train_index], eval_metric=evaluate_macroF1_lgb,\n",
    "              eval_set=eval_set, early_stopping_rounds=100, verbose=100)\n",
    "    model_list_1.append(model)\n",
    "    score_list.append(f1_score(y_train[test_index], model.predict(X_train[test_index]), average='macro'))\n",
    "    \n",
    "print(score_list)\n",
    "print(np.mean(score_list), np.std(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.174286\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.117143\n",
      "[200]\tvalidation_0-merror:0.113571\n",
      "[300]\tvalidation_0-merror:0.107143\n",
      "[400]\tvalidation_0-merror:0.107143\n",
      "Stopping. Best iteration:\n",
      "[343]\tvalidation_0-merror:0.105714\n",
      "\n",
      "[0]\tvalidation_0-merror:0.170714\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.119286\n",
      "[200]\tvalidation_0-merror:0.113571\n",
      "[300]\tvalidation_0-merror:0.108571\n",
      "[400]\tvalidation_0-merror:0.105714\n",
      "[500]\tvalidation_0-merror:0.107143\n",
      "Stopping. Best iteration:\n",
      "[400]\tvalidation_0-merror:0.105714\n",
      "\n",
      "[0]\tvalidation_0-merror:0.182143\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.125714\n",
      "[200]\tvalidation_0-merror:0.115\n",
      "[300]\tvalidation_0-merror:0.110714\n",
      "[400]\tvalidation_0-merror:0.110714\n",
      "Stopping. Best iteration:\n",
      "[343]\tvalidation_0-merror:0.107857\n",
      "\n",
      "[0]\tvalidation_0-merror:0.177143\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.125714\n",
      "[200]\tvalidation_0-merror:0.116429\n",
      "[300]\tvalidation_0-merror:0.118571\n",
      "Stopping. Best iteration:\n",
      "[213]\tvalidation_0-merror:0.115714\n",
      "\n",
      "[0]\tvalidation_0-merror:0.162857\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.12\n",
      "[200]\tvalidation_0-merror:0.109286\n",
      "[300]\tvalidation_0-merror:0.107143\n",
      "[400]\tvalidation_0-merror:0.101429\n",
      "[500]\tvalidation_0-merror:0.097143\n",
      "Stopping. Best iteration:\n",
      "[495]\tvalidation_0-merror:0.095714\n",
      "\n",
      "[0.8584563101944069, 0.8657443532968743, 0.8605366735749139, 0.8506035402325263, 0.8786078622630117]\n",
      "0.8627897479123465 0.009287638221097638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_macroF1_xgb(predictions, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    pred_labels = predictions.reshape(len(np.unique(labels)), -1).argmax(axis=0)\n",
    "    f1 = f1_score(labels, pred_labels, average='macro')\n",
    "    return 'macroF1', 1-f1\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "\n",
    "model_list_2 = []\n",
    "score_list = []\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    model = xgb.XGBClassifier(n_estimators=1000, objective='multi:softmax', num_leaves=63,\n",
    "                               max_depth=7, learning_rate=0.03, subsample=0.8, colsample_bytree=0.8)\n",
    "    eval_set = [(X_train[test_index], y_train[test_index])]\n",
    "    model.fit(X_train[train_index], y_train[train_index], eval_set=eval_set,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    model_list_2.append(model)\n",
    "    score_list.append(f1_score(y_train[test_index], model.predict(X_train[test_index]), average='macro'))\n",
    "    \n",
    "print(score_list)\n",
    "print(np.mean(score_list), np.std(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for model in model_list_1:\n",
    "    result.append(model.predict(X_train))\n",
    "    \n",
    "for model in model_list_2:\n",
    "    result.append(model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(np.array(result).T).mode(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
