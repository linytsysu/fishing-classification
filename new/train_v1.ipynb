{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = pd.read_csv('train_preprocess_v1.csv').values\n",
    "test_data_1 = pd.read_csv('test_preprocess_v1.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2 = pd.read_csv('train_preprocess_v2.csv').values\n",
    "test_data_2 = pd.read_csv('test_preprocess_v2.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_3 = pd.read_csv('train_preprocess_v3.csv').values\n",
    "test_data_3 = pd.read_csv('test_preprocess_v3.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_4 = pd.read_csv('train_preprocess_v4.csv').values\n",
    "test_data_4 = pd.read_csv('test_preprocess_v4.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 920), (7000, 1537), (7000, 38), (7000, 1752))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1.shape, train_data_2.shape, train_data_3.shape, train_data_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = np.concatenate([train_data_1, train_data_2, train_data_3, train_data_4], axis=1)\n",
    "X_test_all = np.concatenate([test_data_1, test_data_2, test_data_3, test_data_4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_df = pd.read_csv('label.csv', header=None)\n",
    "y_train = label_df[0].values\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502 features with a correlation magnitude greater than 0.90.\n",
      "\n",
      "Removed 502 features.\n"
     ]
    }
   ],
   "source": [
    "from feature_selector import FeatureSelector\n",
    "\n",
    "fs = FeatureSelector(data=pd.DataFrame(X_train_all), labels=y_train)\n",
    "\n",
    "fs.identify_collinear(correlation_threshold=0.90)\n",
    "\n",
    "train_no_coll_df = fs.remove(methods = ['collinear'])\n",
    "test_no_coll_df = pd.DataFrame(X_test_all)[train_no_coll_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "selector = VarianceThreshold(0.2)\n",
    "X_train_var = selector.fit_transform(imputer.fit_transform(train_no_coll_df.replace([np.inf, -np.inf], np.nan).values))\n",
    "X_test_var = selector.transform(imputer.fit_transform(test_no_coll_df.replace([np.inf, -np.inf], np.nan).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 3280), (2000, 3280))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_var.shape, X_test_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 1640), (2000, 1640))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold\n",
    "\n",
    "rfe = RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.9000000000000001,\n",
    "                                         n_estimators=100), step=0.15000000000000002)\n",
    "\n",
    "rfe.fit(X_train_var, y_train)\n",
    "\n",
    "\n",
    "X_train_sub_1 = X_train_var[:, rfe.support_]\n",
    "X_test_sub_1 = X_test_var[:, rfe.support_]\n",
    "\n",
    "X_train_sub_1.shape, X_test_sub_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 820), (2000, 820))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.9000000000000001,\n",
    "                                         n_estimators=100), step=0.15000000000000002)\n",
    "\n",
    "rfe.fit(X_train_sub_1, y_train)\n",
    "\n",
    "X_train_sub_2 = X_train_sub_1[:, rfe.support_]\n",
    "X_test_sub_2 = X_test_sub_1[:, rfe.support_]\n",
    "\n",
    "X_train_sub_2.shape, X_test_sub_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 410), (2000, 410))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.9000000000000001,\n",
    "                                         n_estimators=100), step=0.15000000000000002)\n",
    "\n",
    "rfe.fit(X_train_sub_2, y_train)\n",
    "\n",
    "X_train_sub_3 = X_train_sub_2[:, rfe.support_]\n",
    "X_test_sub_3 = X_test_sub_2[:, rfe.support_]\n",
    "\n",
    "X_train_sub_3.shape, X_test_sub_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 205), (2000, 205))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.9000000000000001,\n",
    "                                         n_estimators=100), step=0.15000000000000002)\n",
    "\n",
    "rfe.fit(X_train_sub_3, y_train)\n",
    "\n",
    "X_train_sub_4 = X_train_sub_3[:, rfe.support_]\n",
    "X_test_sub_4 = X_test_sub_3[:, rfe.support_]\n",
    "\n",
    "X_train_sub_4.shape, X_test_sub_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 102), (2000, 102))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.9000000000000001,\n",
    "                                         n_estimators=100), step=0.1)\n",
    "\n",
    "rfe.fit(X_train_sub_4, y_train)\n",
    "\n",
    "X_train_sub_5 = X_train_sub_4[:, rfe.support_]\n",
    "X_test_sub_5 = X_test_sub_4[:, rfe.support_]\n",
    "\n",
    "X_train_sub_5.shape, X_test_sub_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8450006921602006, 0.8771330042547852, 0.8629475921657391, 0.8615475971309241, 0.8629758108193352]\n",
      "0.8619209393061968 0.010198115883483\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_macroF1_lgb(truth, predictions):  \n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True) \n",
    "\n",
    "kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "\n",
    "model_list_1 = []\n",
    "score_list = []\n",
    "for train_index, test_index in kf.split(X_train_sub_5):\n",
    "    model = lgb.LGBMClassifier(n_estimators=1000, objective='multiclass', num_leaves=63,\n",
    "                               max_depth=7, learning_rate=0.03, subsample=0.8, colsample_bytree=0.8)\n",
    "    eval_set = (X_train_sub_5[test_index], y_train[test_index])\n",
    "    model.fit(X=X_train_sub_5[train_index], y=y_train[train_index], eval_metric=evaluate_macroF1_lgb,\n",
    "              eval_set=eval_set, early_stopping_rounds=100, verbose=0)\n",
    "    model_list_1.append(model)\n",
    "    score_list.append(f1_score(y_train[test_index], model.predict(X_train_sub_5[test_index]), average='macro'))\n",
    "    \n",
    "print(score_list)\n",
    "print(np.mean(score_list), np.std(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17  62  71  61   8  66  12  53  93  16  63  19  76  49  98  72  99   5\n",
      "  37  78  96  21  55  31  54  43  95  39  29   2  97  81  10  27  51  86\n",
      "  52  77  92  30  28  22  33  89  73  85  75  45   1  32   3  35  20   6\n",
      "  82  40  90 101  65  11  42  84  64  80  18  87   9  74   4  13  25  70\n",
      "  94  68  69  59  83  26  91  60  15  41  36   0  48  88  46  44  58   7\n",
      " 100  79  38  47  50  23  34  24  14  56  57  67]\n"
     ]
    }
   ],
   "source": [
    "importances_1 = None\n",
    "for model in model_list_1:\n",
    "    if importances_1 is None:\n",
    "        importances_1 = model.feature_importances_\n",
    "    else:\n",
    "        importances_1 = importances_1 + model.feature_importances_\n",
    "print(importances_1.argsort()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8579684624940369, 0.8763748252006675, 0.8697491357188434, 0.8557879852009572, 0.8782115525252889]\n",
      "0.8676183922279588 0.009235907162900412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_macroF1_xgb(predictions, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    pred_labels = predictions.reshape(len(np.unique(labels)), -1).argmax(axis=0)\n",
    "    f1 = f1_score(labels, pred_labels, average='macro')\n",
    "    return 'macroF1', 1-f1\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "\n",
    "model_list_2 = []\n",
    "score_list = []\n",
    "for train_index, test_index in kf.split(X_train_sub_5):\n",
    "    model = xgb.XGBClassifier(n_estimators=1000, objective='multi:softmax', num_leaves=63,\n",
    "                               max_depth=7, learning_rate=0.03, subsample=0.8, colsample_bytree=0.8)\n",
    "    eval_set = [(X_train_sub_5[test_index], y_train[test_index])]\n",
    "    model.fit(X_train_sub_5[train_index], y_train[train_index], eval_set=eval_set,\n",
    "              early_stopping_rounds=100, verbose=0)\n",
    "    model_list_2.append(model)\n",
    "    score_list.append(f1_score(y_train[test_index], model.predict(X_train_sub_5[test_index]), average='macro'))\n",
    "    \n",
    "print(score_list)\n",
    "print(np.mean(score_list), np.std(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71   4  17  30  31  61  40  53  19  51   2  49  56   8  62  43  57  38\n",
      "  12  55  78  50  29  81   6   5  86  66   3  59  60  96  80 100  16  20\n",
      "  41  15  52  99  21  48  90  10  28  64  45   0  24  95  39  33  54  37\n",
      "  58   7  14  25  42  93  87  73  76  35  77  22  84  79  13  68  97  11\n",
      "  89  70  85  63  32  27  82 101  65  44  67  46  98  34  23  74  47   1\n",
      "  92  18  88  75  91  36  69   9  72  83  26  94]\n"
     ]
    }
   ],
   "source": [
    "importances_2 = None\n",
    "for model in model_list_2:\n",
    "    if importances_2 is None:\n",
    "        importances_2 = model.feature_importances_\n",
    "    else:\n",
    "        importances_2 = importances_2 + model.feature_importances_\n",
    "print(importances_2.argsort()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = np.union1d(importances_1.argsort()[::-1][:5], importances_2.argsort()[::-1][:5])\n",
    "important_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_important = X_train_sub_5[:, important_features]\n",
    "X_test_important = X_test_sub_5[:, important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generate_manually():\n",
    "    train_path = '../data/hy_round1_train_20200102'\n",
    "    test_path = '../data/hy_round1_testA_20200102'\n",
    "\n",
    "    train_df_list = []\n",
    "    for file_name in os.listdir(train_path):\n",
    "        df = pd.read_csv(os.path.join(train_path, file_name))\n",
    "        train_df_list.append(df)\n",
    "\n",
    "    test_df_list = []\n",
    "    for file_name in os.listdir(test_path):\n",
    "        df = pd.read_csv(os.path.join(test_path, file_name))\n",
    "        test_df_list.append(df)\n",
    "\n",
    "    train_df = pd.concat(train_df_list)\n",
    "    test_df = pd.concat(test_df_list)\n",
    "\n",
    "    train_df['time'] = pd.to_datetime(train_df['time'], format='%m%d %H:%M:%S')\n",
    "    test_df['time'] = pd.to_datetime(test_df['time'], format='%m%d %H:%M:%S')\n",
    "\n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "    new_df = all_df.groupby('渔船ID').agg(x_min=('x', 'min'), x_max=('x', 'max'), x_mean=('x', 'mean'), x_std=('x', 'std'), x_skew=('x', 'skew'), x_sum=('x', 'sum'),\n",
    "                y_min=('y', 'min'), y_max=('y', 'max'), y_mean=('y', 'mean'), y_std=('y', 'std'), y_skew=('y', 'skew'), y_sum=('y', 'sum'),\n",
    "                v_min=('速度', 'min'), v_max=('速度', 'max'), v_mean=('速度', 'mean'), v_std=('速度', 'std'), v_skew=('速度', 'skew'), v_sum=('速度', 'sum'),\n",
    "                d_min=('方向', 'min'), d_max=('方向', 'max'), d_mean=('方向', 'mean'), d_std=('方向', 'std'), d_skew=('方向', 'skew'), d_sum=('方向', 'sum'))\n",
    "    new_df['x_max-x_min'] = new_df['x_max'] - new_df['x_min']\n",
    "    new_df['y_max-y_min'] = new_df['y_max'] - new_df['y_min']\n",
    "    new_df['x_max-y_min'] = new_df['x_max'] - new_df['y_min']\n",
    "    new_df['y_max-x_min'] = new_df['y_max'] - new_df['x_min']\n",
    "\n",
    "    new_df['slope'] = new_df['y_max-y_min'] / np.where(new_df['x_max-x_min']==0, 0.001, new_df['x_max-x_min'])\n",
    "    new_df['area'] = new_df['x_max-x_min'] * new_df['y_max-y_min']\n",
    "\n",
    "    new_df['type'] = all_df.groupby('渔船ID').agg(type=('type', 'first'))['type'].values\n",
    "\n",
    "    X_train = new_df.drop(columns=['type']).iloc[:7000]\n",
    "    y_train = new_df.iloc[:7000]['type']\n",
    "\n",
    "    X_test = new_df.drop(columns=['type']).iloc[7000:]\n",
    "\n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "def feature_generate_tsfresh():\n",
    "    train_df = pd.read_csv('../history/train.csv')\n",
    "    X_train = train_df.drop(columns=['type'])\n",
    "    y_train = train_df['type']\n",
    "\n",
    "    test_df = pd.read_csv('../history/test.csv')\n",
    "    X_test = test_df[X_train.columns]\n",
    "\n",
    "    base_model = lgb.LGBMClassifier(n_estimators=1000, subsample=0.8)\n",
    "    base_model.fit(X_train.values, y_train)\n",
    "\n",
    "    selected_columns = X_train.columns[np.argsort(base_model.feature_importances_)[::-1][:24]]\n",
    "    print(selected_columns)\n",
    "\n",
    "    X_train = X_train[selected_columns]\n",
    "    X_test = X_test[selected_columns]\n",
    "\n",
    "    X_train_manully, _, X_test_manully = feature_generate_manually()\n",
    "\n",
    "    X_train['x_max-x_min'] = X_train_manully['x_max-x_min'].values\n",
    "    X_test['x_max-x_min'] = X_test_manully['x_max-x_min'].values\n",
    "    X_train['x_max-y_min'] = X_train_manully['x_max-y_min'].values\n",
    "    X_test['x_max-y_min'] = X_test_manully['x_max-y_min'].values\n",
    "    X_train['y_max-x_min'] = X_train_manully['y_max-x_min'].values\n",
    "    X_test['y_max-x_min'] = X_test_manully['y_max-x_min'].values\n",
    "    X_train['y_max-y_min'] = X_train_manully['y_max-y_min'].values\n",
    "    X_test['y_max-y_min'] = X_test_manully['y_max-y_min'].values\n",
    "\n",
    "    X_train['slope'] = X_train_manully['slope'].values\n",
    "    X_test['slope'] = X_test_manully['slope'].values\n",
    "    X_train['area'] = X_train_manully['area'].values\n",
    "    X_test['area'] = X_test_manully['area'].values\n",
    "    \n",
    "    for column in list(X_test.columns[X_test.isnull().sum() > 0]):\n",
    "        mean_val = X_test[column].mean()\n",
    "        X_test[column].fillna(mean_val, inplace=True)\n",
    "\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x__quantile__q_0.1', 'x__minimum', 'y__quantile__q_0.9', 'y__maximum',\n",
      "       'x__quantile__q_0.2', 'y__quantile__q_0.8', 'y__quantile__q_0.7',\n",
      "       '速度__number_crossing_m__m_1', 'y__minimum', 'x__quantile__q_0.3',\n",
      "       '速度__agg_autocorrelation__f_agg_\"median\"__maxlag_40',\n",
      "       'y__number_cwt_peaks__n_1', 'x__maximum', 'x__quantile__q_0.9',\n",
      "       '速度__quantile__q_0.7', 'x__quantile__q_0.4',\n",
      "       '方向__ar_coefficient__k_10__coeff_0', 'y__quantile__q_0.6',\n",
      "       '速度__fft_coefficient__coeff_6__attr_\"real\"',\n",
      "       '方向__fft_coefficient__coeff_64__attr_\"abs\"',\n",
      "       '速度__ratio_beyond_r_sigma__r_2',\n",
      "       'x__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_0__w_2',\n",
      "       'y__fft_coefficient__coeff_6__attr_\"angle\"',\n",
      "       '速度__agg_autocorrelation__f_agg_\"mean\"__maxlag_40'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_train_tsfresh, y_train, X_test_tsfresh = feature_generate_tsfresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat = np.concatenate([X_train_tsfresh.values], axis=1)\n",
    "X_test_concat = np.concatenate([X_test_tsfresh.values], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.303469\tvalid_0's macroF1: 0.863354\n",
      "[200]\tvalid_0's multi_logloss: 0.262285\tvalid_0's macroF1: 0.874823\n",
      "[300]\tvalid_0's multi_logloss: 0.248333\tvalid_0's macroF1: 0.879888\n",
      "[400]\tvalid_0's multi_logloss: 0.245759\tvalid_0's macroF1: 0.883678\n",
      "Early stopping, best iteration is:\n",
      "[355]\tvalid_0's multi_logloss: 0.244523\tvalid_0's macroF1: 0.883678\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.291884\tvalid_0's macroF1: 0.866632\n",
      "[200]\tvalid_0's multi_logloss: 0.252675\tvalid_0's macroF1: 0.877922\n",
      "[300]\tvalid_0's multi_logloss: 0.244308\tvalid_0's macroF1: 0.886179\n",
      "[400]\tvalid_0's multi_logloss: 0.241206\tvalid_0's macroF1: 0.883278\n",
      "Early stopping, best iteration is:\n",
      "[308]\tvalid_0's multi_logloss: 0.244085\tvalid_0's macroF1: 0.888171\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.31689\tvalid_0's macroF1: 0.840088\n",
      "[200]\tvalid_0's multi_logloss: 0.275391\tvalid_0's macroF1: 0.857003\n",
      "[300]\tvalid_0's multi_logloss: 0.264824\tvalid_0's macroF1: 0.859149\n",
      "[400]\tvalid_0's multi_logloss: 0.26197\tvalid_0's macroF1: 0.86277\n",
      "[500]\tvalid_0's multi_logloss: 0.262319\tvalid_0's macroF1: 0.868533\n",
      "Early stopping, best iteration is:\n",
      "[475]\tvalid_0's multi_logloss: 0.260829\tvalid_0's macroF1: 0.863175\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.289276\tvalid_0's macroF1: 0.859423\n",
      "[200]\tvalid_0's multi_logloss: 0.24605\tvalid_0's macroF1: 0.874832\n",
      "[300]\tvalid_0's multi_logloss: 0.231856\tvalid_0's macroF1: 0.883355\n",
      "[400]\tvalid_0's multi_logloss: 0.230049\tvalid_0's macroF1: 0.887646\n",
      "[500]\tvalid_0's multi_logloss: 0.230372\tvalid_0's macroF1: 0.889817\n",
      "Early stopping, best iteration is:\n",
      "[436]\tvalid_0's multi_logloss: 0.229296\tvalid_0's macroF1: 0.891045\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.29085\tvalid_0's macroF1: 0.871026\n",
      "[200]\tvalid_0's multi_logloss: 0.253075\tvalid_0's macroF1: 0.87886\n",
      "[300]\tvalid_0's multi_logloss: 0.243698\tvalid_0's macroF1: 0.88386\n",
      "[400]\tvalid_0's multi_logloss: 0.243877\tvalid_0's macroF1: 0.88845\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's multi_logloss: 0.242712\tvalid_0's macroF1: 0.889033\n",
      "[0.8836783716158009, 0.8881705130466785, 0.8631745088988202, 0.8910449461701591, 0.8890331890331891]\n",
      "0.8830203057529296 0.010211395181765281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "\n",
    "model_list_1 = []\n",
    "score_list = []\n",
    "for train_index, test_index in kf.split(X_train_concat):\n",
    "    model = lgb.LGBMClassifier(n_estimators=1000, objective='multiclass', num_leaves=63,\n",
    "                               max_depth=8, learning_rate=0.035, subsample=0.8, colsample_bytree=0.8)\n",
    "    eval_set = (X_train_concat[test_index], y_train[test_index])\n",
    "    model.fit(X=X_train_concat[train_index], y=y_train[train_index], eval_metric=evaluate_macroF1_lgb,\n",
    "              eval_set=eval_set, early_stopping_rounds=100, verbose=100)\n",
    "    model_list_1.append(model)\n",
    "    score_list.append(f1_score(y_train[test_index], model.predict(X_train_concat[test_index]), average='macro'))\n",
    "    \n",
    "print(score_list)\n",
    "print(np.mean(score_list), np.std(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.158571\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.110714\n",
      "[200]\tvalidation_0-merror:0.099286\n",
      "[300]\tvalidation_0-merror:0.092857\n",
      "[400]\tvalidation_0-merror:0.085714\n",
      "[500]\tvalidation_0-merror:0.082143\n",
      "Stopping. Best iteration:\n",
      "[495]\tvalidation_0-merror:0.081429\n",
      "\n",
      "[0]\tvalidation_0-merror:0.158571\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.100714\n",
      "[200]\tvalidation_0-merror:0.090714\n",
      "[300]\tvalidation_0-merror:0.09\n",
      "Stopping. Best iteration:\n",
      "[263]\tvalidation_0-merror:0.087857\n",
      "\n",
      "[0]\tvalidation_0-merror:0.180714\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.117143\n",
      "[200]\tvalidation_0-merror:0.107857\n",
      "[300]\tvalidation_0-merror:0.105\n",
      "[400]\tvalidation_0-merror:0.1\n",
      "[500]\tvalidation_0-merror:0.102143\n",
      "Stopping. Best iteration:\n",
      "[433]\tvalidation_0-merror:0.098571\n",
      "\n",
      "[0]\tvalidation_0-merror:0.164286\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.110714\n",
      "[200]\tvalidation_0-merror:0.095\n",
      "[300]\tvalidation_0-merror:0.087857\n",
      "[400]\tvalidation_0-merror:0.085\n",
      "Stopping. Best iteration:\n",
      "[396]\tvalidation_0-merror:0.083571\n",
      "\n",
      "[0]\tvalidation_0-merror:0.154286\n",
      "Will train until validation_0-merror hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-merror:0.106429\n",
      "[200]\tvalidation_0-merror:0.096429\n",
      "[300]\tvalidation_0-merror:0.091429\n",
      "[400]\tvalidation_0-merror:0.088571\n",
      "[500]\tvalidation_0-merror:0.086429\n",
      "Stopping. Best iteration:\n",
      "[491]\tvalidation_0-merror:0.085\n",
      "\n",
      "[0.896259754343436, 0.8945390261686744, 0.86652428254967, 0.8986214580074409, 0.8924918271117427]\n",
      "0.8896872696361928 0.011755393076664466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_macroF1_xgb(predictions, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    pred_labels = predictions.reshape(len(np.unique(labels)), -1).argmax(axis=0)\n",
    "    f1 = f1_score(labels, pred_labels, average='macro')\n",
    "    return 'macroF1', 1-f1\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "\n",
    "model_list_2 = []\n",
    "score_list = []\n",
    "for train_index, test_index in kf.split(X_train_concat):\n",
    "    model = xgb.XGBClassifier(n_estimators=1000, objective='multi:softmax', num_leaves=63,\n",
    "                               max_depth=7, learning_rate=0.035, subsample=0.8, colsample_bytree=0.8)\n",
    "    eval_set = [(X_train_concat[test_index], y_train[test_index])]\n",
    "    model.fit(X_train_concat[train_index], y_train[train_index], eval_set=eval_set,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    model_list_2.append(model)\n",
    "    score_list.append(f1_score(y_train[test_index], model.predict(X_train_concat[test_index]), average='macro'))\n",
    "    \n",
    "print(score_list)\n",
    "print(np.mean(score_list), np.std(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 30)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 1, ..., 1, 2, 0]),\n",
       " array([1, 2, 1, ..., 1, 2, 1]),\n",
       " array([1, 2, 1, ..., 1, 2, 1]),\n",
       " array([1, 2, 1, ..., 1, 2, 0]),\n",
       " array([1, 2, 1, ..., 0, 2, 0]),\n",
       " array([1, 2, 1, ..., 1, 2, 0]),\n",
       " array([1, 2, 1, ..., 1, 2, 1]),\n",
       " array([1, 2, 1, ..., 0, 2, 1]),\n",
       " array([1, 2, 1, ..., 1, 2, 0]),\n",
       " array([1, 2, 1, ..., 0, 2, 0])]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for model in model_list_1:\n",
    "    result.append(model.predict(X_test_concat))\n",
    "\n",
    "for model in model_list_2:\n",
    "    result.append(model.predict(X_test_concat))\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[0. 2.]\n",
      "[1. 2.]\n",
      "[0. 2.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n"
     ]
    }
   ],
   "source": [
    "for v in pd.DataFrame(np.array(result).T).mode(axis=1).values:\n",
    "    if not np.isnan(v[1]):\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(np.array(result).T).mode(axis=1)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = [le.inverse_transform([int(p)])[0] for p in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_list, index=range(7000, 9000)).to_csv('result.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
